{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8xfcH6_0bxzC",
    "outputId": "a4dc92bd-24b6-4f7f-f0b3-80ebe8917fff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ CUDA is available.\n",
      "🖥️ GPU Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✅ CUDA is available.\")\n",
    "    print(\"🖥️ GPU Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"❌ CUDA (GPU) is not available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tYs137o3VCMR",
    "outputId": "4a9635c4-e1ad-4327-88e6-88428ed8c38f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m110.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "33a0e0d7f87e4a179312d54b27230c3f",
       "pip_warning": {
        "packages": [
         "nvidia"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install transformers accelerate torch pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C3wWXT0Xi8-F",
    "outputId": "951cfecf-fb6d-4d6d-86d0-433a1f186749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install pandas PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ulxXvNH2koFp",
    "outputId": "8b6e60ef-4dd7-485b-9f6a-ac6e3f5a9e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
      "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.11/dist-packages (3.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch accelerate PyPDF2 pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "tjv2ifdC7fXJ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5JX9LpnG8AbJ"
   },
   "outputs": [],
   "source": [
    "def load_model_pipeline():\n",
    "    model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    hf_token = \"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\"\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, token=hf_token)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"auto\", torch_dtype=torch.float16, token=hf_token)\n",
    "    generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kLQlML208gx9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_technical_questions(directory):\n",
    "    questions = []\n",
    "    for file in os.listdir(directory):\n",
    "        if file.lower().endswith(\".pdf\"):\n",
    "            reader = PdfReader(os.path.join(directory, file))\n",
    "            for page in reader.pages:\n",
    "                text = page.extract_text()\n",
    "                if text:\n",
    "                    questions += [line.strip() for line in text.split(\"\\n\") if line.strip()]\n",
    "        elif file.lower().endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, file), \"r\", encoding=\"utf-8\") as f:\n",
    "                questions += [line.strip() for line in f if line.strip()]\n",
    "    return questions[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9e1gM_hk8pAN"
   },
   "outputs": [],
   "source": [
    "def get_candidate_profile():\n",
    "    print(\"📥 Enter Candidate Information:\")\n",
    "    name = input(\"👤 Name: \")\n",
    "    education = input(\"🎓 Education: \")\n",
    "    skills = input(\"🛠️ Skills (comma-separated): \").split(\",\")\n",
    "    experience = input(\"📈 Experience: \")\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"education\": education,\n",
    "        \"skills\": [s.strip() for s in skills],\n",
    "        \"experience\": experience\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "QeN7LpRi8sTI"
   },
   "outputs": [],
   "source": [
    "def build_prompt(profile, tech_examples=None):\n",
    "    tech_part = \"\"\n",
    "    if tech_examples:\n",
    "        tech_part = \"\\nHere are some sample technical questions:\\n\" + \"\\n\".join(f\"- {q}\" for q in tech_examples)\n",
    "\n",
    "    return f\"\"\"<s>[INST]\n",
    "You are an expert AI interviewer.\n",
    "\n",
    "Candidate Profile:\n",
    "- Name: {profile['name']}\n",
    "- Education: {profile['education']}\n",
    "- Skills: {', '.join(profile['skills'])}\n",
    "- Experience: {profile['experience']}\n",
    "{tech_part}\n",
    "\n",
    "Your Task:\n",
    "1. Generate five (5) customized technical interview questions tailored to the candidate.\n",
    "2. Generate three (3) behavioral interview questions relevant to internship scenarios.\n",
    "\n",
    "Only return the questions in list format. Avoid general questions from Google. Make them practical but not impossible.\n",
    "[/INST]\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BfD2wt1U82e_"
   },
   "outputs": [],
   "source": [
    "def run_interview_question_generator():\n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "\n",
    "    # Step 1: Ask user if they want to upload files\n",
    "    use_files = input(\"📂 Do you want to upload technical question files? (y/n): \").lower() == 'y'\n",
    "    tech_qs = []\n",
    "    if use_files:\n",
    "        print(\"📤 Please upload your PDF/TXT files...\")\n",
    "        uploaded = files.upload()\n",
    "        temp_dir = \"/content/tech_qs\"\n",
    "        os.makedirs(temp_dir, exist_ok=True)\n",
    "        for file in uploaded.keys():\n",
    "            shutil.move(file, os.path.join(temp_dir, file))\n",
    "        tech_qs = extract_technical_questions(temp_dir)\n",
    "\n",
    "    # Step 2: Take profile\n",
    "    profile = get_candidate_profile()\n",
    "\n",
    "    # Step 3: Build prompt\n",
    "    prompt = build_prompt(profile, tech_qs)\n",
    "\n",
    "    # Step 4: Load model\n",
    "    print(\"⏳ Loading model...\")\n",
    "    generator = load_model_pipeline()\n",
    "\n",
    "    # Step 5: Generate questions\n",
    "    print(\"🧠 Generating Interview Questions...\\n\")\n",
    "    output = generator(prompt, max_new_tokens=512, temperature=0.7, top_p=0.9)[0]['generated_text']\n",
    "\n",
    "    # Step 6: Display nicely\n",
    "    print(\"\\n📌 Final Output:\\n\")\n",
    "    print(f\"📍 Intern Profile:\")\n",
    "    print(f\"Name: {profile['name']}\")\n",
    "    print(f\"Education: {profile['education']}\")\n",
    "    print(f\"Skills: {', '.join(profile['skills'])}\")\n",
    "    print(f\"Experience: {profile['experience']}\\n\")\n",
    "\n",
    "    # Assuming the model output format is consistent for splitting\n",
    "    try:\n",
    "        # Split the output to separate technical and behavioral questions\n",
    "        parts = output.split(\"1. Create five (5) customized technical interview questions for this candidate.\")\n",
    "        if len(parts) > 1:\n",
    "            generated_questions_text = parts[1].strip()\n",
    "            tech_behavior_split = generated_questions_text.split(\"2. Create three (3) customized behavioral interview questions for internship scenarios.\")\n",
    "\n",
    "            print(\"🧠 Customized Technical Questions:\")\n",
    "            if len(tech_behavior_split) > 0:\n",
    "                tech_questions_raw = tech_behavior_split[0].strip()\n",
    "                tech_questions = [q.strip() for q in tech_questions_raw.split('\\n') if q.strip()]\n",
    "                for i, q in enumerate(tech_questions, 1):\n",
    "                    print(f\"{i}. {q}\")\n",
    "\n",
    "            print(\"\\n💬 Behavioral Interview Questions:\")\n",
    "            if len(tech_behavior_split) > 1:\n",
    "                behavioral_questions_raw = tech_behavior_split[1].strip()\n",
    "                behavioral_questions = [q.strip() for q in behavioral_questions_raw.split('\\n') if q.strip()]\n",
    "                for i, q in enumerate(behavioral_questions, 1):\n",
    "                    print(f\"{i}. {q}\")\n",
    "            else:\n",
    "                 print(\"Could not extract behavioral questions.\")\n",
    "        else:\n",
    "            print(\"Could not parse generated questions.\")\n",
    "            print(output) # Print raw output if parsing fails\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while parsing the output: {e}\")\n",
    "        print(\"\\nRaw Model Output:\")\n",
    "        print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "ea485bf875c54ce985d0be580760fd0d",
      "27866f9393f4484d8bdaf9716f837b88",
      "078093c081ed43a0a3312365311d0fb8",
      "966859d306ad4542ae5c1a161e6fe913",
      "efb4fe127fb94830a9f440e3c822e62b",
      "fd297fd0cd8e4fa6b4c42aa6a78d36c6",
      "ee800e3ac3cd482396d5b34978c73bec",
      "b23d5f7e204042d6b499c2d79e9c9c43",
      "5b9a8a4fc79049d59361064203c59121",
      "5d7997216d25406fa6d6067d882bbc47",
      "e5e2ef44fe4644588a53348d7c8fa169",
      "e75d6eb2dc3a48209a07ea12ceca4dba",
      "9252a585d89b4b509c779ce6eee8e656",
      "e9327833821b4c6fae36c1050d18e42a",
      "ca54bb11a1ff455b98a4ebc1f4b1b4b8",
      "5da49a4aed614943bbe4936356d2fac3",
      "1acd8a457e4b486397f6beee0b8c24ed",
      "7e0dec67b6df40ab880fa2a2bf9a2f31",
      "50a74a29f2fd4d669558f9039c088db8",
      "ed635ae1285c4686b818d90f9cf87ea0",
      "076e3de3fb4a4f2a8c53c96c4ffa386a",
      "38b43b898ae7488e84d6cb7feeeb85b9",
      "a58f50c73b084d8e911498470b83c4b3",
      "bc82e4e7758643488ff1f042adc36136",
      "c4720c4d2f16422a90bc638ccf0eba52",
      "268fed95404c4e869a993b08d42631bb",
      "b1da417bc37a44ca872c4b74abff0e84",
      "fa840b5166314b189c7039c77c977940",
      "bd2d4c6cfc0847739fd7c62b7b19d684",
      "9ef9eaa4dc854eb1a959a407b4d7be06",
      "1ad5909768ce4c44bbbb02e44177d2bc",
      "febe23c2a6cc46b39ac73fa173a3c7a3",
      "0c0e244f56f64bc29b9e395dede31224",
      "7635996f8c6b47a599dddaed1ddf68e1",
      "d9f5a1d17c184a12879fc8155efa7bbd",
      "0fe3ec0c9b3a4b7dba3f510f2f074c97",
      "89bd645eab1046e9aecb637af0a7da27",
      "5c29a8c20a454b6a960759c864481d68",
      "0b40b76ddfe24b7eafbcaf91e37df989",
      "0b6ed2b1b8ff46f1bea45180a0b58813",
      "9e4d6057a2814ffa8e87b6daa3e4e412",
      "42c2a17f152649fc956eb8acd83ab67f",
      "3fadf106374546e2b909c4906ad248b6",
      "b05000ef47aa40379e7fdbba5b03dba2",
      "ade63fd9b3224ede96b13d09ef049adc",
      "829166a86e924352be73274264e5b4cc",
      "470d3a8db1814c39a33337e65f6ad66d",
      "b04e8f9c32d946d68b21ea3aec9fcc7b",
      "0425b524d301445bb4c26a26517d6f66",
      "4489452e026f4f1ebf1a769c95f8e00f",
      "af5554ce375a4e6ea4289d149dc4a15b",
      "60162f2f71bf41f79ccb04f9224c37a2",
      "c373d2b441054625b95555066d5fd5ed",
      "6f3115af2367446b8a2f6630113470d7",
      "8a8af7be3cdf4a23b2f577d3ee8fb2dd",
      "e80c0c0b530047ababe4149aa62c1bfd",
      "3dcec7d729d84affbe4b9c018ec5c3ff",
      "6c77c292af8b4c3c84e7fb9a27fd0308",
      "d1dd147869ed4534b0fc68e76bb9a6af",
      "b9d9fc97bdbf4f29beb7d05513d358b9",
      "b4d7cafd71be495ab386a953b2f359ac",
      "380a1152915b4d24b6d759d397e61e47",
      "ace1284b7ad04d40a47fb5070b10574c",
      "045679a5be6f49e7a53a11bab4ddeda1",
      "5da5ad011a2842c8a22bf1008150f9cd",
      "cac8017c6c864f51804fc25a75d8483d",
      "c2b90c5c885045ebbca62d719838c7d6",
      "54bedbfd5ce14091a327d86ebe6030f9",
      "36f5358ae18b4fc089158440e587ce96",
      "10293bd3533d41f79ceb63e2852b752e",
      "6ef107fb04c7417eb0620d8d9d45ad08",
      "9c8ddc5a23d14a6eb03bb08ed4c31557",
      "a6bdeb35d3f5462eb8744f7b21821859",
      "2c61cac95f4b4a63bb04dcd41ddae30f",
      "81386385044a4f79ab2baed48001f474",
      "50bd15afd7fa426493c56d541fb3840d",
      "2b6af04b8d494dcb950bcf0c800ee014",
      "33340f9c6eb343bea2c82f7042327b20",
      "28072ede7fba430491c62cce271923bc",
      "137ab8e0e09a49b48aed37d4fca6422d",
      "744d6f300fa64f95a5277657d2c0e7b2",
      "14ea531d8d444408a9f588aefb42dcda",
      "2f684140f5174dd48f1f2c48442bb5fb",
      "cb7659182c524f639c68382af032d65a",
      "5134258b803a44bbb6a2f627f8e3a15c",
      "1158db442bc64d96a7461a229163a958",
      "b93ffabdc4c54cbea7908ef775300edc",
      "8b16e09aee8f430e83299e5641db74a2",
      "69ca7762afa0469caa3f6b5a02f49703",
      "3a9a0cf473c54f5eb52b662dc60c545f",
      "c32dab128d4b47cca2a1ff0e043c5c50",
      "4bf5f6f6529545469f523f982e04fbb1",
      "5d412ef45d6f45b8ad4d3979373483ee",
      "87db9f01e7ec4a2599b85ebe208ab754",
      "5fe72ac4d920484cb643cd2215d0532e",
      "204775f4a455452cb9031dcdd2b4283a",
      "ceed8d1ef2a845b9b195d0012bd695cd",
      "9c5174a6305f434c9d8c11955c9417e2",
      "fa20cb263c14422b94d0dbfa61df6c35",
      "806e3cd3503d445d96859957325f052f",
      "4dee1cd533064b5e8b23d79abf79920a",
      "8c4ebfdb42814c968695207698bbd95d",
      "d5d2aabdaffd43839b3774d9610468b1",
      "637739acd6e2492aacca6979e2fe3d48",
      "7fc70d6e35164c85a717131866a47b89",
      "5a381d31946c48f08500d8436f8a21af",
      "8029b7fdf7094550ae9cad2f5b433cb2",
      "39dc3ef9dad4496caec71def87c6b94c",
      "d790d2e7980f4c8eaf8cab3b67885038",
      "3f4b6ee65b3b4ec6b7ccb39f4f0d0d10",
      "778c98f9745e4b099bcf22dab5d6d8ea",
      "f724bf14f68a4e1386cfb1068a7f0d8a",
      "8570bed8ac874488a50f3f61ab7b05bf",
      "05f7e9943451419dbe223d665ec253a6",
      "aa1bffe1d2524b02a29ea4ac5bcc6f3e",
      "937b941821e04c22810455b7b06de9ef",
      "92d4bf3d2d44433f9c14b453e16db87f",
      "dd07462315074f8193123ed8019d0341",
      "96008adb679c442bb39aad65044668fa",
      "b1fe6d9aa96e47779e78a6cee2ffb9ce",
      "5792a8e0d066430e93355dc3d5003e0d"
     ]
    },
    "id": "CFMtEdL-9o_G",
    "outputId": "9e788f68-bd11-40d8-843f-f36c0c563636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📂 Do you want to upload technical question files? (y/n): n\n",
      "📥 Enter Candidate Information:\n",
      "👤 Name: Ali\n",
      "🎓 Education: BS in AI\n",
      "🛠️ Skills (comma-separated): python,DNN,CV,ML\n",
      "📈 Experience: internship of 2 months\n",
      "⏳ Loading model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea485bf875c54ce985d0be580760fd0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75d6eb2dc3a48209a07ea12ceca4dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58f50c73b084d8e911498470b83c4b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7635996f8c6b47a599dddaed1ddf68e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ade63fd9b3224ede96b13d09ef049adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80c0c0b530047ababe4149aa62c1bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2b90c5c885045ebbca62d719838c7d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33340f9c6eb343bea2c82f7042327b20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69ca7762afa0469caa3f6b5a02f49703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806e3cd3503d445d96859957325f052f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778c98f9745e4b099bcf22dab5d6d8ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧠 Generating Interview Questions...\n",
      "\n",
      "\n",
      "📌 Final Output:\n",
      "\n",
      "📍 Intern Profile:\n",
      "Name: Ali\n",
      "Education: BS in AI\n",
      "Skills: python, DNN, CV, ML\n",
      "Experience: internship of 2 months\n",
      "\n",
      "Could not parse generated questions.\n",
      "<s>[INST]\n",
      "You are an expert AI interviewer.\n",
      "\n",
      "Candidate Profile:\n",
      "- Name: Ali\n",
      "- Education: BS in AI\n",
      "- Skills: python, DNN, CV, ML\n",
      "- Experience: internship of 2 months\n",
      "\n",
      "\n",
      "Your Task:\n",
      "1. Generate five (5) customized technical interview questions tailored to the candidate.\n",
      "2. Generate three (3) behavioral interview questions relevant to internship scenarios.\n",
      "\n",
      "Only return the questions in list format. Avoid general questions from Google. Make them practical but not impossible.\n",
      "[/INST]  Sure, here are five customized technical interview questions tailored to Ali's profile:\n",
      "\n",
      "1. Can you explain the differences between a convolutional neural network (CNN) and a recurrent neural network (RNN), and provide an example of a scenario where one might be more appropriate than the other?\n",
      "2. How would you approach building a deep learning model for image classification, and what preprocessing techniques would you use to prepare the data before training?\n",
      "3. Can you explain the concept of overfitting in machine learning, and how can you prevent it in a deep learning model? Provide an example of a technique you might use to address overfitting in a real-world scenario.\n",
      "4. How would you design a neural network architecture for natural language processing tasks, such as sentiment analysis or text classification? Can you walk me through the process of selecting the appropriate layers and hyperparameters for the task at hand?\n",
      "5. Can you explain the concept of transfer learning, and how it can be used to improve the performance of a deep learning model? Provide an example of a scenario where transfer learning might be particularly useful.\n",
      "\n",
      "And here are three behavioral interview questions relevant to Ali's internship experience:\n",
      "\n",
      "1. Can you tell me about a project you worked on during your internship, and how you contributed to its success? What did you learn from the experience, and how has it prepared you for your future career in AI?\n",
      "2. How do you stay current with the latest developments in the field of AI? Can you give me an example of a recent paper or article you read that you found particularly interesting or impactful?\n",
      "3. Can you describe a time when you had to work with a team to solve a complex problem in AI? How did you handle any challenges or conflicts that arose during the project, and what was the final outcome?\n"
     ]
    }
   ],
   "source": [
    "run_interview_question_generator()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
